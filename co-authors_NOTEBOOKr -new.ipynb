{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# import time \n",
    "# from selenium.webdriver.support.ui import Select\n",
    "# import pandas as pd\n",
    "# import openpyxl\n",
    "# import re\n",
    "# import os\n",
    "# import glob\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.get('https://scholar.google.com/citations?view_op=search_authors')\n",
    "# search_bttn = driver.find_element(By.XPATH, '//*[@id=\"gs_hdr_tsi\"]')\n",
    "# search_bttn.send_keys(\"Radwan,A.\")\n",
    "# click_search_btnn =   driver.find_element(By.XPATH, '//*[@id=\"gs_hdr_tsb\"]/span/span[1]').click()\n",
    "# click_on_author = driver.find_element(By.XPATH, '//*[@id=\"gsc_sa_ccl\"]/div[1]/div/div/h3/a').click()\n",
    "# publication_links = driver.find_elements(By.CSS_SELECTOR, '#gsc_a_b .gsc_a_t a')\n",
    "# print(publication_links)\n",
    "# click_on_first_publication =  driver.find_element(By.XPATH, '//*[@id=\"gsc_a_b\"]/tr[1]/td[1]/a').click()\n",
    "# click_on_pub_link =  driver.find_element(By.XPATH,'//*[@id=\"gsc_oci_title_gg\"]/div').click()\n",
    "# click_on_email_icon = driver.find_element(By.XPATH,'//*[@id=\"author-group\"]/button[1]/span/span[1]').click()\n",
    "# copy_email =  driver.find_element(By.XPATH,'//*[@id=\"side-panel-author\"]/div[3]/a/span').text\n",
    "# print(copy_email)\n",
    "# click_on_email_icon_2 = driver.find_element(By.XPATH, '//*[@id=\"author-group\"]/button[2]').click()\n",
    "# copy_email_2 = driver.find_element(By.XPATH,'//*[@id=\"side-panel-author\"]/div[4]/a/span').text\n",
    "# print(copy_email_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First sample \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def extract_strings_with_at_symbol(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  \n",
    "        if response.status_code == 200:\n",
    "            html_content = response.text\n",
    "            at_symbol_pattern = r'\\b\\S*@\\S*\\b'\n",
    "            strings_with_at_symbol = re.findall(at_symbol_pattern, html_content)\n",
    "            if strings_with_at_symbol:\n",
    "             \n",
    "                return strings_with_at_symbol\n",
    "            else:\n",
    "                return []\n",
    "        else:\n",
    "            print(f\"Failed to retrieve content from {url}. Status code: {response.status_code}\")\n",
    "            return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred during request: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting strings: {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    website_url = \"https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/algorithms-in-bioinformatics/\"\n",
    "    extracted_strings = extract_strings_with_at_symbol(website_url)\n",
    "    if extracted_strings:\n",
    "        print(\"Strings containing '@' found on the website:\")\n",
    "        for string in extracted_strings:\n",
    "            print(string)\n",
    "    else:\n",
    "        print(\"No strings containing '@' found on the website.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get co-author ids and names and domain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "def extract_first_column_values(file_path):\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        first_column_values = df.iloc[:, 0].tolist()\n",
    "        return first_column_values\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting first column values: {e}\")\n",
    "        return None\n",
    "ids= []\n",
    "excel_file_path = \"/Users/nu/Documents/GitHub/Scopus-/coauthors.xlsx\"\n",
    "first_column_values = extract_first_column_values(excel_file_path)\n",
    "if first_column_values:\n",
    "    print(\"First Column Values:\")\n",
    "    for value in first_column_values:\n",
    "        ids.append(value)\n",
    "else:\n",
    "    print(\"Failed to extract first column values.\")\n",
    "\n",
    "print(ids)\n",
    "df = pd.DataFrame(columns=[\"author id\", \"author name\", \"author indexed name\"])\n",
    "for author_id in ids:\n",
    "    url = f\"https://api.elsevier.com/content/author/author_id/{author_id}?apiKey=89a1ebfbce5e0a87b9c189b908fed168\"\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': '89a1ebfbce5e0a87b9c189b908fed168'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Retry until successful\n",
    "    while response.status_code != 200:\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "    data = response.json()\n",
    "    author_responses = data.get('author-retrieval-response', [])\n",
    "\n",
    "    for author_data in author_responses:\n",
    "        if 'author-profile' in author_data:\n",
    "            profile = author_data['author-profile']\n",
    "\n",
    "          \n",
    "            preferred_name = profile.get('preferred-name', {})\n",
    "            full_name = f\"{preferred_name.get('given-name', '')} {preferred_name.get('surname', '')}\"\n",
    "\n",
    "         \n",
    "            indexed_names = []\n",
    "            name_variants = profile.get('name-variant', [])\n",
    "            if isinstance(name_variants, list):\n",
    "                indexed_names = [f\"{nv.get('given-name', '')} {nv.get('surname', '')}\" for nv in name_variants[:2]]\n",
    "            elif isinstance(name_variants, dict):  \n",
    "                indexed_names.append(f\"{name_variants.get('given-name', '')} {name_variants.get('surname', '')}\")\n",
    "\n",
    "            # Join indexed names with a comma\n",
    "            indexed_names_str = ', '.join(indexed_names)\n",
    "            print(indexed_names_str)\n",
    "            try:\n",
    "                org = author_data['author-profile']['affiliation-current']['affiliation']['ip-doc']['org-domain']\n",
    "                print(\"domain\", org)\n",
    "            except TypeError:\n",
    "               res = author_data['author-profile']['affiliation-current']['affiliation']\n",
    "               org_domain = None\n",
    "               if res and 'ip-doc' in res[0]:    \n",
    "                    org = res[0]['ip-doc'].get('org-domain', None)\n",
    "                    print(\"second\", org)\n",
    "               else:\n",
    "                   org = 'None'\n",
    "            except KeyError:\n",
    "                org = 'NA'\n",
    "\n",
    "\n",
    "            row_data = {\n",
    "                \"author id\": str(author_id),\n",
    "                \"author name\": full_name,\n",
    "                \"author indexed name\": indexed_names_str,\n",
    "                \"domain\":org\n",
    "            }\n",
    "            # Create a DataFrame for the new row and concatenate it with the existing DataFrame\n",
    "            df = df._append(row_data, ignore_index=True)\n",
    "            df.to_excel('co-author.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the made url to google search and get the first link and get all string that conatins @ in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "data = pd.read_excel('co-author.xlsx')\n",
    "API_KEY = 'AIzaSyDheJ4Rf-TtaqvJ0DNX8A5X6FKThrhyU3w'\n",
    "CSE_ID = 'a6b7d695ce59e4d26'\n",
    "\n",
    "def find_first_url(query):\n",
    "    \"\"\"Use Google Custom Search JSON API to search for the query and return the first result URL.\"\"\"\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        'key': API_KEY,\n",
    "        'cx': CSE_ID,\n",
    "        'q': query,\n",
    "        'num': 1  \n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  \n",
    "        search_results = response.json()\n",
    "        print(search_results)\n",
    "        first_result_url = search_results['items'][0]['link'] if 'items' in search_results else None\n",
    "        print(first_result_url)\n",
    "        return first_result_url\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP Error for search '{query}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for '{query}': {e}\")\n",
    "    return None\n",
    "\n",
    "def scrape_for_emails(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = [line for line in text.split() if '@' in line]\n",
    "        print(emails)\n",
    "        return emails\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching emails from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "df = pd.DataFrame(columns=[\"email\"])\n",
    "for query in data['search_by'].dropna():\n",
    "    first_url = find_first_url(query)\n",
    "    if first_url:\n",
    "        emails = scrape_for_emails(first_url)\n",
    "        new_row = pd.DataFrame({'email': [emails]})\n",
    "       \n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "     \n",
    "    else:\n",
    "        print(f\"No URL found for {query}\")\n",
    "    time.sleep(1)  \n",
    "\n",
    "df.to_excel('emails2.xlsx', index=False)\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Query: {data['search_by'][index]}, Emails: {row['email']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import backoff\n",
    "\n",
    "# Load the Excel file\n",
    "data = pd.read_excel('co-author.xlsx')\n",
    "\n",
    "\n",
    "API_KEY = 'AIzaSyDheJ4Rf-TtaqvJ0DNX8A5X6FKThrhyU3w'\n",
    "CSE_ID = 'a6b7d695ce59e4d26'\n",
    "\n",
    "@backoff.on_exception(backoff.expo,\n",
    "                      requests.exceptions.RequestException,\n",
    "                      max_tries=8)\n",
    "def make_request(url, params):\n",
    "    \"\"\"Make HTTP GET request with given URL and parameters.\"\"\"\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()  # Raises an exception for HTTP errors\n",
    "    return response.json()\n",
    "\n",
    "def find_first_url(query):\n",
    "    \"\"\"Use Google Custom Search JSON API to search for the query and return the first result URL.\"\"\"\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        'key': API_KEY,\n",
    "        'cx': CSE_ID,\n",
    "        'q': query,\n",
    "        'num': 1  # Number of search results to return\n",
    "    }\n",
    "    try:\n",
    "        search_results = make_request(url, params)\n",
    "        print(search_results)\n",
    "        first_result_url = search_results['items'][0]['link'] if 'items' in search_results else None\n",
    "        print(first_result_url)\n",
    "        return first_result_url\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP Error for search '{query}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for '{query}': {e}\")\n",
    "    return None\n",
    "\n",
    "def scrape_for_emails(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = [line for line in text.split() if '@' in line]\n",
    "        print(emails)\n",
    "        return emails\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching emails from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "df = pd.DataFrame(columns=[\"email\"])\n",
    "\n",
    "for query in data['search_by'].dropna():\n",
    "    first_url = find_first_url(query)\n",
    "    if first_url:\n",
    "        emails = scrape_for_emails(first_url)\n",
    "        new_row = pd.DataFrame({'email': [emails]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"No URL found for {query}\")\n",
    "    time.sleep(1)  \n",
    "\n",
    "df.to_excel('emails4.xlsx', index=False)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Query: {data['search_by'][index]}, Emails: {row['email']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "data = pd.read_excel('co-author.xlsx')\n",
    "API_KEY = 'your_api_key'\n",
    "CSE_ID = 'your_custom_search_engine_id'\n",
    "\n",
    "def find_first_url(query):\n",
    "    \"\"\"Use Google Custom Search JSON API to search for the query and return the first result URL.\"\"\"\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        'key': API_KEY,\n",
    "        'cx': \"52f467de3fbcf4ca0\",\n",
    "        'q': query,\n",
    "        'num': 1\n",
    "    }\n",
    "    for attempt in range(5):  # Retry up to 5 times\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            search_results = response.json()\n",
    "            first_result_url = search_results['items'][0]['link'] if 'items' in search_results else None\n",
    "            return first_result_url\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                print(f\"Rate limit exceeded. Retrying in {attempt * 10} seconds...\")\n",
    "                time.sleep(attempt * 10 + randint(5, 10))  # Backoff with some randomness to avoid synchronization\n",
    "            else:\n",
    "                print(f\"HTTP Error for search '{query}': {e}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{query}': {e}\")\n",
    "            break\n",
    "    return None\n",
    "\n",
    "def scrape_for_emails(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = [line for line in text.split() if '@' in line]\n",
    "        return emails\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching emails from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "df = pd.DataFrame(columns=[\"email\"])\n",
    "for query in data['search_by'].dropna():\n",
    "    first_url = find_first_url(query)\n",
    "    if first_url:\n",
    "        emails = scrape_for_emails(first_url)\n",
    "        new_row = pd.DataFrame({'email': [emails]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"No URL found for {query}\")\n",
    "    time.sleep(randint(1, 3))  # Random delay between 1 to 3 seconds\n",
    "\n",
    "df.to_excel('emails4.xlsx', index=False)\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Query: {data['search_by'][index]}, Emails: {row['email']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'book' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Append the result to the dataframe and save to Excel immediately\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memail\u001b[39m\u001b[38;5;124m'\u001b[39m: [emails]})\n\u001b[1;32m---> 71\u001b[0m     new_row\u001b[38;5;241m.\u001b[39mto_excel(writer, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, startrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mbook\u001b[49m\u001b[38;5;241m.\u001b[39mactive[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     72\u001b[0m     writer\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m     74\u001b[0m request_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'book' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Attempt to open an existing workbook or create a new one if it doesn't exist\n",
    "try:\n",
    "    book = load_workbook('emails_found.xlsx')\n",
    "    writer = pd.ExcelWriter('emails_found.xlsx', engine='openpyxl') \n",
    "    writer.book = book\n",
    "    writer.sheets = {ws.title: ws for ws in book.worksheets}\n",
    "except FileNotFoundError:\n",
    "    writer = pd.ExcelWriter('emails_found.xlsx', engine='openpyxl')\n",
    "df = pd.DataFrame(columns=[\"email\"])\n",
    "\n",
    "data = pd.read_excel('co-author.xlsx')\n",
    "API_KEY = 'AIzaSyDheJ4Rf-TtaqvJ0DNX8A5X6FKThrhyU3w'\n",
    "CSE_ID = 'a6b7d695ce59e4d26'\n",
    "\n",
    "def find_first_url(query):\n",
    "    \"\"\"Use Google Custom Search JSON API to search for the query and return the first result URL.\"\"\"\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        'key': API_KEY,\n",
    "        'cx': CSE_ID,\n",
    "        'q': query,\n",
    "        'num': 1  \n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  \n",
    "        search_results = response.json()\n",
    "        first_result_url = search_results['items'][0]['link'] if 'items' in search_results else None\n",
    "        return first_result_url\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP Error for search '{query}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for '{query}': {e}\")\n",
    "    return None\n",
    "\n",
    "def scrape_for_emails(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = [line for line in text.split() if '@' in line]\n",
    "        return emails\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching emails from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "request_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for query in data['search_by'].dropna():\n",
    "    if request_count >= 10:\n",
    "        # Calculate elapsed time and sleep if less than 60 seconds\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time < 60:\n",
    "            time.sleep(60 - elapsed_time)\n",
    "        # Reset the timer and request count\n",
    "        start_time = time.time()\n",
    "        request_count = 0\n",
    "\n",
    "    first_url = find_first_url(query)\n",
    "    if first_url:\n",
    "        emails = scrape_for_emails(first_url)\n",
    "        # Append the result to the dataframe and save to Excel immediately\n",
    "        new_row = pd.DataFrame({'email': [emails]})\n",
    "        new_row.to_excel(writer, index=False, header=False, startrow=len(book.active['A'])+1)\n",
    "        writer.save()\n",
    "\n",
    "    request_count += 1\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'OK', 'request_id': '19b388b2-7107-44bd-bff9-35dc0dc728d3', 'data': [{'email': 'daniel.huson@uni-tuebingen.de', 'sources': ['https://journals.asm.org/doi/pdf/10.1128/genomea.01220-17', 'https://journals.plos.org/ploscompbiol/article/authors?id=10.1371/journal.pcbi.1004957', 'https://github.com/husonlab/jloda/blob/master/LICENSE', 'https://academic.oup.com/gbe/article-abstract/8/4/1197/2574103', 'https://fit.uni-tuebingen.de/Portfolio/Details?id=546', 'https://publikationen.uni-tuebingen.de/xmlui/bitstream/10900/89082/1/Lange%20Dissertation.pdf', 'https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE3MTcyODA0OTEsImV4cCI6MTcxNzM3MDQ5MCwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0Zha3VsdGFldGVuXC9JbmZvS29nbmlcL1dTSVwvRG9rdW1lbnRlXC9TdHVkaXVtXC9Eb3dubG9hZFwvQWt0dWVsbGVzX1NlbWVzdGVyXC9NYXN0ZXJzQmlvaW5mb3JtYXRpY3NfV2VsY29tZV9TUzI0LnBkZiIsInBhZ2UiOjc0MzUxfQ.Ih3JrBb_Z_rHaCyJR3Zx5jMPWbn3DxSky8N26kzG9Ho/MastersBioinformatics_Welcome_SS24.pdf', 'https://github.com/husonlab/SplitsPy/blob/main/setup.py']}, {'email': 'daniel.huson@.uni-tuebingen.de', 'sources': ['https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/algorithms-in-bioinformatics']}, {'email': 'huson@informatik.uni-tuebingen.de', 'sources': ['https://pubmed.ncbi.nlm.nih.gov/19189494', 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=106b631437a0413be2a46e2e1fcbdf75211f4f60', 'https://ae.iti.kit.edu/1615.php', 'https://academic.oup.com/bioinformatics/article/20/13/2044/241946', 'https://books.google.com/books?id=vsBrCQAAQBAJ&pg=PA150&lpg=PA150&dq=%22Daniel+H.+Huson%22+%22*%5B@%5Duni-tuebingen.de%22&source=bl&ots=imQi0u9WfB&sig=ACfU3U2mqVfw5Gfr-RMpYp1GaUkI2ietNA&hl=en']}, {'email': 'daniel.menning@uni-tuebingen.de', 'sources': ['https://www.welcomecenter.uni-tuebingen.de/register.php']}, {'email': 'daniel.merling@student.uni-tuebingen.de', 'sources': ['https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE3MTY4Mjg5MTEsImV4cCI6MTcxNjkxODkwOCwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0Zha3VsdGFldGVuXC9JbmZvS29nbmlcL1dTSVwvQ29tR3JhcGhcL3RlYWNoaW5nXC9Tb1NlMTZcL0luZm9fSUlcL0luZm8yLTAxLUVpbmZ1ZWhydW5nLnBkZiIsInBhZ2UiOjc3Mjg3fQ.gC59d-TLYr41OkxFyPR9WwtwUBpga57JBvBVlYqAgDQ/Info2-01-Einfuehrung.pdf']}, {'email': 'stefanie.frick@med.uni-tuebingen.de', 'sources': ['https://academic.oup.com/gbe/article-abstract/8/4/1197/2574103', 'https://publikationen.uni-tuebingen.de/xmlui/bitstream/10900/89082/1/Lange%20Dissertation.pdf']}, {'email': 'julia-stefanie.frick@med.uni-tuebingen.de', 'sources': ['https://journals.asm.org/doi/pdf/10.1128/genomea.01220-17', 'https://academic.oup.com/gbe/article-abstract/8/4/1197/2574103']}, {'email': 'gabriele.abels@uni-tuebingen.de', 'sources': ['https://www.welcomecenter.uni-tuebingen.de/register.php']}, {'email': 'andreas.peschel@uni-tuebingen.de', 'sources': ['https://bibliographie.uni-tuebingen.de/xmlui/bitstream/handle/10900/96839/ClaudiaSauer.pdf?sequence=1']}, {'email': 'delgado@informatik.uni-tuebingen.de', 'sources': ['https://subs.emis.de/LNI/Proceedings/Proceedings53/GI-Proceedings.53-2.pdf', 'https://www.researchgate.net/publication/221493476_Syntenic_Layout_of_Two_Assemblies_of_Related_Genomes', 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=fc8f64ae93d239114ab53481b721a4ad21f0e420']}, {'email': 'rausch@informatik.uni-tuebingen.de', 'sources': ['https://subs.emis.de/LNI/Proceedings/Proceedings53/GI-Proceedings.53-2.pdf', 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=fc8f64ae93d239114ab53481b721a4ad21f0e420']}, {'email': 'prevention@uni-tuebingen.de', 'sources': ['https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/systems-biology/team/draeger', 'https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/algorithms-in-bioinformatics/people/daniel-huson']}, {'email': 'l.angenent@uni-tuebingen.de', 'sources': ['https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2020.594524/full', 'https://fit.uni-tuebingen.de/Portfolio/Details?id=2713']}, {'email': 'sina.beier@uni-tuebingen.de', 'sources': ['https://peerj.com/preprints/1350.pdf']}, {'email': 'alfons.renz@uni-tuebingen.de', 'sources': ['https://publikationen.uni-tuebingen.de/xmlui/bitstream/handle/10900/100702/Guimbang%20Abanda%20Babette%20%20Dissertation.pdf?isAllowed=y&sequence=1']}, {'email': 'nadine.ziemert@uni-tuebingen.de', 'sources': ['https://antimicrobialresistance.dk/CustomerData/Files/Folders/10-seqafrica/116_alanjary-2019-automlst.pdf', 'https://fit.uni-tuebingen.de/Portfolio/Details?id=1512']}, {'email': 'bastian.molitor@uni-tuebingen.de', 'sources': ['https://www.cell.com/iscience/fulltext/S2589-0042(23)02093-X']}, {'email': 'andreas.kappler@uni-tuebingen.de', 'sources': ['https://publikationen.uni-tuebingen.de/xmlui/bitstream/handle/10900/101397/PhD%20thesis-Zhen%20Yang.pdf?sequence=1&isAllowed=y']}, {'email': 'ab-support@inf.uni-tuebingen.de', 'sources': ['https://plabase.cs.uni-tuebingen.de/mm/contact.html']}, {'email': 'mitra@informatik.uni-tuebingen.de', 'sources': ['https://d-nb.info/1008804894/34', 'https://bibliographie.uni-tuebingen.de/xmlui/bitstream/handle/10900/49471/pdf/Thesis.pdf?sequence=1']}, {'email': 'matthew.araz@uni-tuebingen.de', 'sources': ['https://www.frontiersin.org/articles/10.3389/fbioe.2023.1150170']}, {'email': 'hendrik.lensch@uni-tuebingen.de', 'sources': ['https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE3MTY4Mjg5MTEsImV4cCI6MTcxNjkxODkwOCwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0Zha3VsdGFldGVuXC9JbmZvS29nbmlcL1dTSVwvQ29tR3JhcGhcL3RlYWNoaW5nXC9Tb1NlMTZcL0luZm9fSUlcL0luZm8yLTAxLUVpbmZ1ZWhydW5nLnBkZiIsInBhZ2UiOjc3Mjg3fQ.gC59d-TLYr41OkxFyPR9WwtwUBpga57JBvBVlYqAgDQ/Info2-01-Einfuehrung.pdf']}, {'email': 'sascha.patz@uni-tuebingen.de', 'sources': ['https://www.biorxiv.org/content/10.1101/2024.02.17.580828v1']}, {'email': 'kloepper@informatik.uni-tuebingen.de', 'sources': ['https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=106b631437a0413be2a46e2e1fcbdf75211f4f60']}, {'email': 'pfeifer@informatik.uni-tuebingen.de', 'sources': ['https://drops.dagstuhl.de/opus/volltexte/2017/7812/pdf/lipics-vol88-wabi2017-complete.pdf']}, {'email': 'fischer@informatik.uni-tuebingen.de', 'sources': ['https://ae.iti.kit.edu/1615.php']}, {'email': 'christopher.culy@uni-tuebingen.de', 'sources': ['https://aclanthology.org/W12-02.pdf']}, {'email': 'britt.starkovich@uni-tuebingen.de', 'sources': ['https://repositorio.unican.es/xmlui/bitstream/10902/18850/3/HumanBehaviouralAdaptations.pdf']}, {'email': 'gerhard.jaeger@uni-tuebingen.de', 'sources': ['http://www.sfs.uni-tuebingen.de/~gjaeger/publications/asrLDC.pdf']}, {'email': 'thilo.stehle@uni-tuebingen.de', 'sources': ['https://publikationen.uni-tuebingen.de/xmlui/bitstream/handle/10900/97228/PhD_Thesis_DGerlach_noCV.pdf?sequence=1&isAllowed=y']}, {'email': 'inge.seefluth@uni-tuebingen.de', 'sources': ['https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE3MTcxNjcxNzYsImV4cCI6MTcxNzI1NzE3NiwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0FsbGdlbWVpblwvQmlsZGVyXC9uZXdzbGV0dGVyXC9wZGYtRHJ1Y2t2ZXJzaW9uXC9uZXdzbGV0dGVyXzA0LTIwMTAucGRmIiwicGFnZSI6MTU3MTN9.oCN8LaXpBrDQN2uhZRcM9Hg1_WZGfK2qQg-njuUyME4/newsletter_04-2010.pdf']}, {'email': 'pruefungsamt.bioinformatik@uni-tuebingen.de', 'sources': ['https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE3MTcyODA0OTEsImV4cCI6MTcxNzM3MDQ5MCwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0Zha3VsdGFldGVuXC9JbmZvS29nbmlcL1dTSVwvRG9rdW1lbnRlXC9TdHVkaXVtXC9Eb3dubG9hZFwvQWt0dWVsbGVzX1NlbWVzdGVyXC9NYXN0ZXJzQmlvaW5mb3JtYXRpY3NfV2VsY29tZV9TUzI0LnBkZiIsInBhZ2UiOjc0MzUxfQ.Ih3JrBb_Z_rHaCyJR3Zx5jMPWbn3DxSky8N26kzG9Ho/MastersBioinformatics_Welcome_SS24.pdf']}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://email-finder4.p.rapidapi.com/find-emails\"\n",
    "\n",
    "querystring = {\"name\":\"Daniel H. Huson\",\"email_domain\":\"uni-tuebingen.de\"}\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"496d942af8msh75a05d2c5fb1e66p1a0a5cjsne4e59e82f6a3\",\n",
    "\t\"X-RapidAPI-Host\": \"email-finder4.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'OK', 'request_id': 'fd4e0604-c6b3-4c73-8c5e-166f3b06d2ba', 'data': [{'email': 'agradwan@nu.edu.eg', 'sources': ['https://www.academia.edu/91527638/Effect_of_Different_Approximation_Techniques_on_Fractional_Order_KHN_Filter_Design?f_ri=393865', 'https://www.academia.edu/91527641/On_the_Approximations_of_CFOA_Based_Fractional_Order_Inverse_Filters?uc-sb-sw=92643323', 'https://www.spp2100.de/fileadmin/images/ICRA22__Contributed_Papers/08_Design_and_Control_of_Soft_Biomimetic_Pangasius_Fish_Robot_Using_Finray_Actuator_and_Reinforcement_Learning.pdf']}, {'email': 'agradwan@nu.edu.egauthor', 'sources': ['https://ascelibrary.org/doi/10.1061/9780784484852.010']}, {'email': 'mabdelrahman@nu.edu.eg', 'sources': ['https://ngdc.cncb.ac.cn/openlb/publication/OLB-PM-33542318', 'https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=20452322&AN=148498366&h=y1V7dm5VMqz8WwQRjzOxPsKp1YLjpdgTqdLB0I4eciXXnqlKCiLluABiBlQ%2BpUKjSCupkrsPWJcW4PNi2PVFNg%3D%3D&crl=c']}, {'email': 'amadian@nu.edu.eg', 'sources': ['https://link.springer.com/content/pdf/10.1007/s10470-022-02079-y.pdf', 'https://www.academia.edu/91527641/On_the_Approximations_of_CFOA_Based_Fractional_Order_Inverse_Filters?uc-sb-sw=92643323', 'https://pdfs.semanticscholar.org/7984/8591eac93514140dd5fda70295c4a58cf301.pdf', 'https://www.academia.edu/94470095/Plant_Tissue_Modelling_Using_Power_Law_Filters']}, {'email': 'e.hamed@nu.edu.eg', 'sources': ['https://www.academia.edu/91527638/Effect_of_Different_Approximation_Techniques_on_Fractional_Order_KHN_Filter_Design?f_ri=393865']}, {'email': 'msoliman@nu.edu.eg', 'sources': ['https://europepmc.org/article/pmc/pmc8187634', 'https://pdfs.semanticscholar.org/7446/fb520d991de9a1d6679950a552e5ce7870fd.pdf', 'https://www.spp2100.de/fileadmin/images/ICRA22__Contributed_Papers/08_Design_and_Control_of_Soft_Biomimetic_Pangasius_Fish_Robot_Using_Finray_Actuator_and_Reinforcement_Learning.pdf']}, {'email': 'a.hosney@nu.edu.eg', 'sources': ['https://orcid.org/0000-0002-7390-708X']}, {'email': 'm.farrag@nu.edu.eg', 'sources': ['https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=13807501&AN=137078510&h=6ulMlGUxgf%2FbjdhttVwDVogFpQiTZuCV3eLkIErj4n4WJaUA4Y%2Beq92Pc2ae5aOF5L1WvOEeZzTeKsETvUsXPg%3D%3D&crl=c', 'https://rim.ekb.eg/converis/portal/detail/Publication/82224727;jsessionid=iZNDq9XYW7jFUMlayJdTsgwEtPj2739RN_boEbRR.rim1?lang=en_US']}, {'email': 'mabdullah@nu.edu.eg', 'sources': ['https://pdfs.semanticscholar.org/7446/fb520d991de9a1d6679950a552e5ce7870fd.pdf', 'https://www.spp2100.de/fileadmin/images/ICRA22__Contributed_Papers/08_Design_and_Control_of_Soft_Biomimetic_Pangasius_Fish_Robot_Using_Finray_Actuator_and_Reinforcement_Learning.pdf']}, {'email': 'mmansour@nu.edu.eg', 'sources': ['https://ascelibrary.org/doi/10.1061/9780784484852.010']}, {'email': 'mjarrag@nu.edu.eg.wafaasayed', 'sources': ['https://ieeexplore.ieee.org/iel7/8370368/8376555/08376621.pdf']}, {'email': 'amohammaden@nu.edu.eg', 'sources': ['https://hal.science/hal-03667814/file/Mohammaden_2022_electronics-11-01455-v3.pdf', 'https://hal.science/hal-03667814/document']}, {'email': 'sara.mostafa@nu.edu.eg', 'sources': ['https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=02181274&AN=157407274&h=Bgu32EAhj%2FJFSbQ5l5ZeMcHQgs%2FKf6YqVNIYdjUMFY2nZrFs1%2BaQ4JvixiMtHMxzWCRpEaPKOjtX5x3Xm%2FbbRA%3D%3D&crl=f']}, {'email': 'isamy@nu.edu.eg', 'sources': ['https://onlinelibrary.wiley.com/doi/abs/10.1002/masy.202300046', 'http://www.enicbcmed.eu/sites/default/files/2024-05/U-SOLVE_%20Output%204.2.%20New%20entrepreneurial%20ideas.pdf']}, {'email': 'gelmissiry@nu.edu.eg', 'sources': ['https://nu.edu.eg/sites/default/files/2024-01/newsletter_november_compressed_compressed-compressed.pdf']}, {'email': 'lsaid@nu.edu.eg', 'sources': ['https://ascelibrary.org/doi/10.1061/9780784484852.010']}, {'email': 'bhsrl@nu.edu.eg', 'sources': ['https://www.linkedin.com/posts/mahmoodsaleh_job-research-engineering-activity-6999159212916273152-Zyw4', 'https://www.linkedin.com/posts/mahmoodsaleh_biohybridsoftroboticslab-asrt-softrobotics-activity-6894216639798243328-0Q1a']}, {'email': 'sselim@nu.edu.eg', 'sources': ['https://www.scribd.com/document/680269743/eBook-MEDI2022-Springer']}, {'email': 'b.kamal2160@nu.edu.eg', 'sources': ['https://dl.acm.org/doi/fullHtml/10.1145/3627345.3627351']}, {'email': 's.imbaby@nu.edu.eg', 'sources': ['https://typeset.io/pdf/plant-tissue-modelling-using-power-law-filters-3uhk6qc5.pdf']}, {'email': 'icm2016@nu.edu.eg', 'sources': ['https://www.researchgate.net/publication/299588268_ICM2016-1st_CFP_A']}, {'email': 'scholarships@nu.edu.eg', 'sources': ['https://www.linkedin.com/posts/abdulmoneam-ali-02467725_nu-postgraduate-scholarship-for-master-of-activity-7098950065645371392-oa8O?trk=public_profile_share_view']}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://email-finder4.p.rapidapi.com/find-emails\"\n",
    "\n",
    "querystring = {\"name\":\"Ahmed G. Radwan\",\"email_domain\":\"nu.edu.eg\"}\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"496d942af8msh75a05d2c5fb1e66p1a0a5cjsne4e59e82f6a3\",\n",
    "\t\"X-RapidAPI-Host\": \"email-finder4.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'OK', 'request_id': '06644654-2bd1-4a6c-bf93-5f106c9823ab', 'data': [{'email': 'lsaid@nu.edu.eg', 'sources': ['https://palast.ps/sites/default/files/inline-files/AGYA_Call_Training_Academic_Professional_Skills.pdf', 'https://agya.info/fileadmin/user_upload/Press_and_Publications/Calls/2023/2023_3rd_Practical_Training_on_Academic_and_Progessional_Skills/Call_for_Participation_Workshop_and_Training_for_Graduates.pdf', 'https://iceeng.conferences.ekb.eg/page_2393_Conference%20Committee.html', 'https://www.scribd.com/document/455831358/ECEN101-Lecture-1', 'https://hal.science/hal-03667814/file/Mohammaden_2022_electronics-11-01455-v3.pdf', 'https://www.coursehero.com/sitemap/schools/78520-Nile-University/courses/5896956-ECEN101', 'https://typeset.io/pdf/plant-tissue-modelling-using-power-law-filters-3uhk6qc5.pdf', 'https://books.google.com/books?id=erjuEAAAQBAJ&pg=PA153&lpg=PA153&dq=%22Lobna+A.+Said%22+%22*%5B@%5Dnu.edu.eg%22&source=bl&ots=irvb_jYL-F&sig=ACfU3U2Fws28qdAsAAlDaX6HylOuKIaXPw&hl=en', 'https://ascelibrary.org/doi/10.1061/9780784484852.010', 'https://iceeit.org/wp-content/uploads/2022/10/DOC-20221021-WA0018.-1.pdf', 'https://mdpi-res.com/d_attachment/energies/energies-16-03465/article_deploy/energies-16-03465.pdf']}, {'email': 'isamy@nu.edu.eg', 'sources': ['https://www.researchgate.net/publication/371808822_Preparation_and_Characterization_of_nZVI_Bimetallic_Fe-Cu_and_Fava_Bean_Activated_Carbon-Supported_Bimetallic_AC-F_e-Cu_for_Anionic_Methyl_Orange_Dye_Removal', 'https://ascelibrary.org/doi/10.1061/9780784484852.010', 'https://onlinelibrary.wiley.com/doi/abs/10.1002/masy.202300046', 'https://ascelibrary.org/doi/abs/10.1061/9780784484852.010', 'https://books.google.com/books?id=LeoEEQAAQBAJ&pg=PA38&lpg=PA38&dq=%22Lobna+A.+Said%22+%22*%5B@%5Dnu.edu.eg%22&source=bl&ots=3ZTm0034P8&sig=ACfU3U2dzH8qLJzcDfMjQyVp3DC4XZ7DNA&hl=en']}, {'email': 'sara.mostafa@nu.edu.eg', 'sources': ['https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=02181274&AN=157407274&h=Bgu32EAhj%2FJFSbQ5l5ZeMcHQgs%2FKf6YqVNIYdjUMFY2nZrFs1%2BaQ4JvixiMtHMxzWCRpEaPKOjtX5x3Xm%2FbbRA%3D%3D&crl=f', 'https://books.google.com/books?id=6mgFEQAAQBAJ&pg=PA370&lpg=PA370&dq=%22Lobna+A.+Said%22+%22*%5B@%5Dnu.edu.eg%22&source=bl&ots=7AVxgnDNY2&sig=ACfU3U1yl1DRkHiRyltKeZYX7j4L0ddD2Q&hl=en', 'https://books.google.com/books?id=6mgFEQAAQBAJ&pg=PA370&lpg=PA370&dq=Lobna+A.+Said+%22*%5B@%5Dnu.edu.eg%22&source=bl&ots=7AVxgnDNY2&sig=ACfU3U1yl1DRkHiRyltKeZYX7j4L0ddD2Q&hl=en']}, {'email': 'niles.conf@nu.edu.eg', 'sources': ['https://m.facebook.com/photo.php?fbid=595792679404178&id=100069203532358&set=a.425490976434350&locale=fi_FI', 'https://www.linkedin.com/posts/lbnlcs_sc23-iamhpc-hpc-activity-7130971742012915712-0fgu', 'https://es.linkedin.com/posts/iqm-quantum-computers_iqm-quantumcomputing-education-activity-7071836595473063936-DUHO', 'https://www.linkedin.com/posts/elisa-negri-a6496748_conference-simulation-annsim-activity-7100859549355507712-jKRq', 'https://www.linkedin.com/posts/mohamed-el-ouali-9981a172_collaboration-appliedresearch-innovation-activity-7138530604194693120-S1_P', 'https://www.linkedin.com/posts/architecteca2030_conference-itise2023-presentation-activity-7092089178112282624-BJX9', 'https://www.linkedin.com/posts/mlcad_mlcad2024-machinelearning-generativeai-activity-7192398136969977856-pzd9', 'https://www.linkedin.com/posts/yogesh-bothara-25476018b_researchpaper-conferencepublication-icetest2023-activity-7085653118587207680-tA_d']}, {'email': 'mmansour@nu.edu.eg', 'sources': ['https://ascelibrary.org/doi/10.1061/9780784484852.010', 'https://ascelibrary.org/doi/abs/10.1061/9780784484852.010', 'https://mdpi-res.com/d_attachment/energies/energies-16-03465/article_deploy/energies-16-03465.pdf', 'https://books.google.com/books?id=erjuEAAAQBAJ&pg=PA153&lpg=PA153&dq=%22Lobna+A.+Said%22+%22*%5B@%5Dnu.edu.eg%22&source=bl&ots=irvb_jYL-F&sig=ACfU3U2Fws28qdAsAAlDaX6HylOuKIaXPw&hl=en', 'https://books.google.com/books?id=erjuEAAAQBAJ&pg=PA153&lpg=PA153&dq=Lobna+A.+Said+%22*%5B@%5Dnu.edu.eg%22&source=bl&ots=irvb_jYL-F&sig=ACfU3U2Fws28qdAsAAlDaX6HylOuKIaXPw&hl=en']}, {'email': 'amadian@nu.edu.eg', 'sources': ['https://www.researchgate.net/publication/334748239_Stability_analysis_of_fractional-order_Colpitts_oscillators', 'https://link.springer.com/content/pdf/10.1007/s10470-022-02079-y.pdf', 'https://www.wseas.org/multimedia/journals/information/2018/a425909-908.pdf', 'https://www.wseas.org/multimedia/journals/information/2018/a385909-903.pdf']}, {'email': 'gelmissiry@nu.edu.eg', 'sources': ['https://nu.edu.eg/sites/default/files/2024-01/newsletter_november_compressed_compressed-compressed.pdf']}, {'email': 'research.office@nu.edu.eg', 'sources': ['https://m.facebook.com/p/AGYA-Summer-School-in-Numerical-Simulation-100069227880705', 'https://m.facebook.com/permalink.php/?story_fbid=2391144361206269&id=2391138201206885', 'https://m.facebook.com/2391138201206885/photos/a.2398227990497906/2398222223831816/?type=3']}, {'email': 'e.hamed@nu.edu.eg', 'sources': ['https://www.academia.edu/91527638/Effect_of_Different_Approximation_Techniques_on_Fractional_Order_KHN_Filter_Design?f_ri=393865', 'https://rim.ekb.eg/converis/portal/detail/Publication/81650793?auxfun=&lang=en_US']}, {'email': 'agradwan@nu.edu.eg', 'sources': ['https://www.academia.edu/91527638/Effect_of_Different_Approximation_Techniques_on_Fractional_Order_KHN_Filter_Design?f_ri=393865', 'https://ieeexplore.ieee.org/iel7/10217215/10217348/10217720.pdf']}, {'email': 'a.hosney@nu.edu.eg', 'sources': ['https://orcid.org/0000-0002-7390-708X']}, {'email': 'amohammaden@nu.edu.eg', 'sources': ['https://hal.science/hal-03667814/file/Mohammaden_2022_electronics-11-01455-v3.pdf']}, {'email': 'b.kamal2160@nu.edu.eg', 'sources': ['https://dl.acm.org/doi/fullHtml/10.1145/3627345.3627351']}, {'email': 'a.gamal2165@nu.edu.eg', 'sources': ['https://mdpi-res.com/d_attachment/energies/energies-16-03465/article_deploy/energies-16-03465.pdf']}, {'email': 'ah.ahmed@nu.edu.eg', 'sources': ['https://ieeexplore.ieee.org/iel7/9666052/9666199/09666279.pdf', 'https://mdpi-res.com/d_attachment/energies/energies-16-03465/article_deploy/energies-16-03465.pdf']}, {'email': 'sselim@nu.edu.eg', 'sources': ['https://www.scribd.com/document/680269743/eBook-MEDI2022-Springer']}, {'email': 's.imbaby@nu.edu.eg', 'sources': ['https://typeset.io/pdf/plant-tissue-modelling-using-power-law-filters-3uhk6qc5.pdf']}, {'email': 'h.elghamry@nu.edu.eg', 'sources': ['https://www.itu.int/en/ITU-D/Regional-Presence/ArabStates/Documents/events/2020/RDF/RDF2020-ARB-REPORT-E.pdf']}, {'email': 'marketing@nu.edu.eg', 'sources': ['https://www.nu.edu.eg/sites/default/files/2023-08/jan2_01-converted_compressed.pdf']}, {'email': 'scholarships@nu.edu.eg', 'sources': ['https://www.linkedin.com/posts/khloudkhaled19_lucky-me-honored-to-be-involved-and-attending-activity-7074046734284263424-MOdh']}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://email-finder4.p.rapidapi.com/find-emails\"\n",
    "\n",
    "querystring = {\"name\":\"Lobna A. Said\",\"email_domain\":\"nu.edu.eg\"}\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"496d942af8msh75a05d2c5fb1e66p1a0a5cjsne4e59e82f6a3\",\n",
    "\t\"X-RapidAPI-Host\": \"email-finder4.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://rapidapi.com/letscrape-6bRBa3QguO5/api/email-finder4/pricing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
